{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "falling-corner",
   "metadata": {},
   "source": [
    "# Going Deeper 2\n",
    "## 없다면 우야 될까\n",
    "|평가문항|상세기준|\n",
    "|:---|:---|\n",
    "|1. ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?|블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.|\n",
    "|2. 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?|cats_vs_dogs 데이터셋으로 학습시 몇 epoch동안 안정적으로 loss 감소가 진행 확인되었다.|\n",
    "|3. Ablation Study 결과가 바른 포맷으로 제출되었는가?|ResNet-34, ResNet-50 각각 plain모델과 residual모델을 동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "known-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collect-lease",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-newton",
   "metadata": {},
   "source": [
    "- main layer와 skip layer 총 2개를 구현해야함.\n",
    "- skip layers는 stride가 1보다 큰 경우 필요. 입력 x와 출력의 크기가 다른 경우\n",
    "- call() : input 을 main과 skip layers에 통과시킨 후 두 출력을 더해서 활성화 함수 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-rescue",
   "metadata": {},
   "source": [
    "### ResNet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "automotive-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock34(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides = 1, activation= \"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activiation = keras.activations.get(activation)\n",
    "         \n",
    "        ## 34 main layer\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=(3,3),\n",
    "                strides = strides,\n",
    "                padding='same',\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activiation,\n",
    "            keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=(3,3),\n",
    "                strides = 1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        \n",
    "        ## 34 skip layers\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                keras.layers.Conv2D(\n",
    "                    kernel_size=(1,1),\n",
    "                    filters = filters,\n",
    "                    strides = strides,\n",
    "                    padding=\"same\"\n",
    "                ),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        ## main layer\n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            z = layer(z)\n",
    "        \n",
    "        ## skip layer\n",
    "        skip_z = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_z = layer(skip_z)\n",
    "            \n",
    "        return self.activiation(z + skip_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-genius",
   "metadata": {},
   "source": [
    "### ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "front-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The identity block\n",
    "def identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # 1 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F1, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # 2 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F2, \n",
    "        kernel_size=f, \n",
    "        strides=1, \n",
    "        padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # 3 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    # add shortcut value and pass it through a ReLU activation\n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incident-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Block\n",
    "def convolutional_block(X, f, filters, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # first step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F1, \n",
    "        kernel_size=1, \n",
    "        strides=s, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # second step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F2, \n",
    "        kernel_size=f, \n",
    "        strides=1, \n",
    "        padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # third step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    # shortcut path\n",
    "    X_shortcut = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=s, \n",
    "        padding='valid')(X_shortcut)\n",
    "    X_shortcut = tf.keras.layers.BatchNormalization()(X_shortcut)\n",
    "    \n",
    "    # Add and pass it through a ReLU activation\n",
    "    X = tf.keras.layers.Add()([X, X_shortcut])\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorporated-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "def ResNet50(input_shape=(32, 32, 3), classes=10):\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "    # zero padding\n",
    "    X = tf.keras.layers.ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # stage 1\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=64, \n",
    "        kernel_size=7, \n",
    "        strides=2, \n",
    "        name='conv1',\n",
    "        )(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3,3), strides=2)(X)\n",
    "    \n",
    "    # stage 2\n",
    "    X = convolutional_block(\n",
    "        X, \n",
    "        f=3, \n",
    "        filters=[64,64,256]\n",
    "        )\n",
    "    X = identity_block(X, 3, [64,64,256])\n",
    "    X = identity_block(X, 3, [64,64,256])\n",
    "    \n",
    "    # stage 3\n",
    "    X = convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [128, 128, 512], \n",
    "        )\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    # Stage 4\n",
    "    X = convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [256, 256, 1024], \n",
    "        )\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    \n",
    "    # Stage 5\n",
    "    X = convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [512, 512, 2048], \n",
    "        )\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    \n",
    "    # AVGPOOL\n",
    "    # X = tf.keras.layers.AveragePooling2D()(X)\n",
    "    X = tf.keras.layers.GlobalAvgPool2D()(X)\n",
    "    \n",
    "    \n",
    "    # output layer\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Create Model\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-immune",
   "metadata": {},
   "source": [
    "### resnet을 구현하는 함수 build_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noted-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(32, 32,3), is_50=False):\n",
    "    if is_50:\n",
    "        ## 50 cnn block 반복\n",
    "        model = ResNet50(input_shape=input_shape)\n",
    "    else:\n",
    "        ## 채널 종류와 채널 갯수 \n",
    "        num_of_channel = [3, 4, 6, 3]\n",
    "        channel_list = [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "        model = keras.models.Sequential()\n",
    "        ## 앞 부분 con layer와 pooling\n",
    "        model.add(keras.layers.Conv2D(\n",
    "                        input_shape=input_shape,\n",
    "                        filters = 64,\n",
    "                        kernel_size=(7,7),\n",
    "                        strides = 2,\n",
    "                        padding='same',\n",
    "                    ))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Activation(\"relu\"))\n",
    "        model.add(keras.layers.MaxPool2D(\n",
    "            pool_size=(3,3), \n",
    "            strides=2, \n",
    "            padding=\"same\"))\n",
    "\n",
    "        prev_filter = 64\n",
    "\n",
    "        ## 34 cnn block 반복\n",
    "        for (channel, num_channel) in zip(channel_list, num_of_channel):\n",
    "            strides = 1 if channel == prev_filter else 2\n",
    "            model.add(ResidualBlock34(filters = channel, strides= strides))\n",
    "            prev_filter = channel\n",
    "            \n",
    "        ## 마지막 부분 layer\n",
    "        model.add(keras.layers.GlobalAvgPool2D())\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacterial-provider",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 64)        9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "residual_block34 (ResidualBl (None, 8, 8, 64)          74368     \n",
      "_________________________________________________________________\n",
      "residual_block34_1 (Residual (None, 4, 4, 128)         231296    \n",
      "_________________________________________________________________\n",
      "residual_block34_2 (Residual (None, 2, 2, 256)         921344    \n",
      "_________________________________________________________________\n",
      "residual_block34_3 (Residual (None, 1, 1, 512)         3677696   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,919,562\n",
      "Trainable params: 4,913,802\n",
      "Non-trainable params: 5,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_34 = build_resnet(input_shape=(32, 32, 3), is_50=False)\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arctic-taiwan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 64)     4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 64)     256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4, 4, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 64)     36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 64)     256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 4, 64)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 256)    16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 256)    16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 4, 4, 256)    0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 4, 4, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 64)     16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 4, 4, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 4, 4, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 64)     36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 4, 4, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 4, 4, 64)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 4, 256)    16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 4, 256)    1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 4, 256)    0           batch_normalization_19[0][0]     \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 4, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 4, 64)     16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 4, 4, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 4, 4, 64)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 4, 64)     36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 4, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 4, 4, 64)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 4, 256)    16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 4, 256)    1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 4, 4, 256)    0           batch_normalization_22[0][0]     \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 2, 2, 128)    32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 2, 2, 128)    512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2, 2, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 2, 2, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 2, 2, 128)    512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2, 2, 128)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 2, 2, 512)    66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 2, 2, 512)    131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 2, 2, 512)    2048        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 2, 2, 512)    2048        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2, 2, 512)    0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2, 2, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 2, 2, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 2, 2, 128)    512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 2, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 2, 2, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2, 2, 128)    512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 128)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 512)    66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 2, 2, 512)    2048        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2, 2, 512)    0           batch_normalization_29[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 2, 2, 128)    65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 2, 2, 128)    512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2, 2, 128)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 2, 2, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 2, 2, 128)    512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 2, 2, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 2, 2, 512)    66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 2, 2, 512)    2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2, 2, 512)    0           batch_normalization_32[0][0]     \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2, 2, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 2, 2, 128)    65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 2, 2, 128)    512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2, 2, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 2, 2, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 2, 2, 128)    512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 2, 2, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 512)    66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 2, 2, 512)    2048        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2, 2, 512)    0           batch_normalization_35[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 2, 2, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 1, 1, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 1, 1, 256)    1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1, 1, 256)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 1, 1, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 1, 1, 256)    1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1, 1, 256)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 1, 1, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 1, 1, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 1, 1, 1024)   4096        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 1, 1, 1024)   4096        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1, 1, 1024)   0           batch_normalization_38[0][0]     \n",
      "                                                                 batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1, 1, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 1, 1, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 1, 1, 256)    1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1, 1, 256)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 1, 1, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 1, 1, 256)    1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1, 1, 256)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 1, 1, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 1, 1, 1024)   4096        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1, 1, 1024)   0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1, 1, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 1, 1, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 1, 1, 256)    1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1, 1, 256)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 1, 1, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 1, 1, 256)    1024        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1, 1, 256)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 1, 1, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 1, 1, 1024)   4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1, 1, 1024)   0           batch_normalization_45[0][0]     \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1, 1, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 1, 1, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 1, 1, 256)    1024        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1, 1, 256)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 1, 1, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 1, 1, 256)    1024        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 1, 1, 256)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 1, 1, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 1, 1, 1024)   4096        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_48[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1, 1, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 1, 1, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 1, 1, 256)    1024        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1, 1, 256)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 1, 1, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 1, 1, 256)    1024        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1, 1, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 1, 1, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 1, 1, 1024)   4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_51[0][0]     \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1, 1, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 1, 1, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 1, 1, 256)    1024        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1, 1, 256)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 1, 1, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 1, 1, 256)    1024        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1, 1, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 1, 1, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 1, 1, 1024)   4096        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 1, 1, 1024)   0           batch_normalization_54[0][0]     \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1, 1, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 1, 1, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 1, 1, 512)    2048        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1, 1, 512)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 1, 1, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 1, 1, 512)    2048        conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 512)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 1, 1, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 1, 1, 2048)   8192        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 1, 1, 2048)   8192        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_57[0][0]     \n",
      "                                                                 batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 1, 1, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 1, 1, 512)    2048        conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 512)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 1, 1, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 1, 1, 512)    2048        conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 512)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 1, 1, 2048)   8192        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_61[0][0]     \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 1, 1, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 1, 1, 512)    2048        conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 512)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 1, 1, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 1, 1, 512)    2048        conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 512)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 1, 1, 2048)   8192        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_64[0][0]     \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           20490       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_50 = build_resnet(input_shape=(32, 32, 3), is_50=True)\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-router",
   "metadata": {},
   "source": [
    "## 3) 일반 네트워크(plain network) 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-ecuador",
   "metadata": {},
   "source": [
    "### plain block 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fundamental-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlainBlock34(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides = 1, activation= \"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activiation = keras.activations.get(activation)\n",
    "         \n",
    "        ## 34 main layer\n",
    "        self.main_layers = [\n",
    "            keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=(3,3),\n",
    "                strides = strides,\n",
    "                padding='same',\n",
    "            ),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activiation,\n",
    "            keras.layers.Conv2D(\n",
    "                filters=filters,\n",
    "                kernel_size=(3,3),\n",
    "                strides = 1,\n",
    "                padding='same',\n",
    "            ),\n",
    "            keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        \n",
    "            \n",
    "    def call(self, inputs):\n",
    "        ## main layer\n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            z = layer(z)\n",
    "\n",
    "        return self.activiation(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-local",
   "metadata": {},
   "source": [
    "### plain block 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "flexible-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The identity block\n",
    "def plain_identity_block(X, f, filters):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # 1 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F1, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # 2 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F2, \n",
    "        kernel_size=f, \n",
    "        strides=1, \n",
    "        padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # 3 depth\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    # add shortcut value and pass it through a ReLU activation\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "healthy-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Block\n",
    "def plain_convolutional_block(X, f, filters, s=2):\n",
    "    F1, F2, F3 = filters\n",
    "    X_shortcut = X\n",
    "    \n",
    "    # first step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F1, \n",
    "        kernel_size=1, \n",
    "        strides=s, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # second step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F2, \n",
    "        kernel_size=f, \n",
    "        strides=1, \n",
    "        padding='same')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    # third step of main path\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=1, \n",
    "        padding='valid')(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    # shortcut path\n",
    "    X_shortcut = tf.keras.layers.Conv2D(\n",
    "        filters=F3, \n",
    "        kernel_size=1, \n",
    "        strides=s, \n",
    "        padding='valid')(X_shortcut)\n",
    "    X_shortcut = tf.keras.layers.BatchNormalization()(X_shortcut)\n",
    "    \n",
    "    # Add and pass it through a ReLU activation\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "resident-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50\n",
    "def Plain_ResNet50(input_shape=(32, 32, 3), classes=10):\n",
    "    X_input = tf.keras.layers.Input(input_shape)\n",
    "    # zero padding\n",
    "    X = tf.keras.layers.ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # stage 1\n",
    "    X = tf.keras.layers.Conv2D(\n",
    "        filters=64, \n",
    "        kernel_size=7, \n",
    "        strides=2, \n",
    "        name='conv1',\n",
    "        )(X)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Activation('relu')(X)\n",
    "    X = tf.keras.layers.MaxPooling2D((3,3), strides=2)(X)\n",
    "    \n",
    "    # stage 2\n",
    "    X = plain_convolutional_block(\n",
    "        X, \n",
    "        f=3, \n",
    "        filters=[64,64,256]\n",
    "        )\n",
    "    X = plain_identity_block(X, 3, [64,64,256])\n",
    "    X = plain_identity_block(X, 3, [64,64,256])\n",
    "    \n",
    "    # stage 3\n",
    "    X = plain_convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [128, 128, 512], \n",
    "        )\n",
    "    X = plain_identity_block(X, 3, [128, 128, 512])\n",
    "    X = plain_identity_block(X, 3, [128, 128, 512])\n",
    "    X = plain_identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    # Stage 4\n",
    "    X = plain_convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [256, 256, 1024], \n",
    "        )\n",
    "    X = plain_identity_block(X, 3, [256, 256, 1024])\n",
    "    X = plain_identity_block(X, 3, [256, 256, 1024])\n",
    "    X = plain_identity_block(X, 3, [256, 256, 1024])\n",
    "    X = plain_identity_block(X, 3, [256, 256, 1024])\n",
    "    X = plain_identity_block(X, 3, [256, 256, 1024])\n",
    "    \n",
    "    # Stage 5\n",
    "    X = plain_convolutional_block(\n",
    "        X, \n",
    "        f = 3, \n",
    "        filters = [512, 512, 2048], \n",
    "        )\n",
    "    X = plain_identity_block(X, 3, [512, 512, 2048])\n",
    "    X = plain_identity_block(X, 3, [512, 512, 2048])\n",
    "    \n",
    "    # AVGPOOL\n",
    "    # X = tf.keras.layers.AveragePooling2D()(X)\n",
    "    X = tf.keras.layers.GlobalAvgPool2D()(X)\n",
    "    \n",
    "    \n",
    "    # output layer\n",
    "    X = tf.keras.layers.Flatten()(X)\n",
    "    X = tf.keras.layers.Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    # Create Model\n",
    "    model = tf.keras.models.Model(inputs=X_input, outputs=X, name='ResNet50')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-memorial",
   "metadata": {},
   "source": [
    "### plain net을 생성하는 build_plainnet 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "literary-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_plainnet(input_shape=(224, 224, 3), is_50=False):\n",
    "    if is_50:\n",
    "        ## 50 cnn block\n",
    "        model = Plain_ResNet50(input_shape=input_shape)\n",
    "        \n",
    "    else:\n",
    "        ## 34 cnn block\n",
    "        ## 채널 종류와 채널 갯수 \n",
    "        num_of_channel = [3, 4, 6, 3]\n",
    "        channel_list = [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "        model = keras.models.Sequential()\n",
    "        ## 앞 부분 con layer와 pooling\n",
    "        model.add(keras.layers.Conv2D(\n",
    "                        input_shape=input_shape,\n",
    "                        filters = 64,\n",
    "                        kernel_size=(7,7),\n",
    "                        strides = 2,\n",
    "                        padding='same',\n",
    "                    ))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Activation(\"relu\"))\n",
    "        model.add(keras.layers.MaxPool2D(\n",
    "            pool_size=(3,3), \n",
    "            strides=2, \n",
    "            padding=\"same\"))\n",
    "\n",
    "        prev_filter = 64\n",
    "        \n",
    "        ##  반복\n",
    "        for (channel, num_channel) in zip(channel_list, num_of_channel):\n",
    "            strides = 1 if channel == prev_filter else 2\n",
    "            model.add(PlainBlock34(filters = channel, strides= strides))\n",
    "            prev_filter = channel\n",
    "            \n",
    "        ## 마지막 부분 layer\n",
    "        model.add(keras.layers.GlobalAvgPool2D())\n",
    "        model.add(keras.layers.Flatten())\n",
    "        model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "noticed-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "plain_block34 (PlainBlock34) (None, 56, 56, 64)        74368     \n",
      "_________________________________________________________________\n",
      "plain_block34_1 (PlainBlock3 (None, 28, 28, 128)       222464    \n",
      "_________________________________________________________________\n",
      "plain_block34_2 (PlainBlock3 (None, 14, 14, 256)       887296    \n",
      "_________________________________________________________________\n",
      "plain_block34_3 (PlainBlock3 (None, 7, 7, 512)         3544064   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,743,050\n",
      "Trainable params: 4,739,082\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plain_resnet_34 = build_plainnet(input_shape=(224, 224, 3), is_50=False)\n",
    "plain_resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "secret-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 230, 230, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 64)      9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 55, 55, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 28, 28, 64)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 28, 28, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 28, 28, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 28, 28, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 28, 28, 64)        16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 28, 28, 256)       16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 14, 14, 128)       32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 14, 14, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 14, 14, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 14, 14, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 14, 14, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 14, 14, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 14, 14, 128)       65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 14, 14, 512)       66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 7, 7, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 7, 7, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 7, 7, 1024)        263168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_115 (Conv2D)          (None, 4, 4, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_116 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_117 (Conv2D)          (None, 4, 4, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 4, 4, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_121 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_122 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 4, 4, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 4, 4, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_124 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_125 (Bat (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 4, 4, 2048)        1050624   \n",
      "_________________________________________________________________\n",
      "batch_normalization_126 (Bat (None, 4, 4, 2048)        8192      \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 4, 4, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,820,106\n",
      "Trainable params: 20,774,666\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plain_resnet_50 = build_plainnet(input_shape=(224, 224, 3), is_50=True)\n",
    "plain_resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-nirvana",
   "metadata": {},
   "source": [
    "## 4)  resnet 50 vs plain 50,  resnet 34 vs plain 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sustainable-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "blank-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    # image = tf.image.resize(image, [32, 32])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "otherwise-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize_on_dataset(ds, is_test=False, batch_size=16):\n",
    "    ds = ds.map(\n",
    "        normalize_and_resize_img, \n",
    "        num_parallel_calls=1\n",
    "    )\n",
    "    ds = ds.batch(batch_size)\n",
    "    if not is_test:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(200)\n",
    "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-tattoo",
   "metadata": {},
   "source": [
    "cifar10 dataset불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "binary-blink",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /aiffel/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7352440682274d8b8ffb16030a9d0175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a8855496034611afe29a91bea4ec08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d654312d4cd41e98778fe19c2e968b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cifar10-train.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cifar10-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar10 downloaded and prepared to /aiffel/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "#tfds.disable_progress_bar()   # 이 주석을 풀면 데이터셋 다운로드과정의 프로그레스바가 나타나지 않습니다.\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'cifar10',\n",
    "    split=['train', 'test'],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")\n",
    "ds_train = apply_normalize_on_dataset(ds_train, batch_size=BATCH_SIZE)\n",
    "ds_test = apply_normalize_on_dataset(ds_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-composer",
   "metadata": {},
   "source": [
    "### 34 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "polished-chick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9991WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='conv2d_64_input'), name='conv2d_64_input', description=\"created by layer 'conv2d_64_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/195 [==============================] - 20s 78ms/step - loss: 0.0321 - accuracy: 0.9991 - val_loss: 1.8897 - val_accuracy: 0.5528\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0250 - accuracy: 0.9999 - val_loss: 2.0659 - val_accuracy: 0.5399\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.0680 - val_accuracy: 0.5542\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.0572 - val_accuracy: 0.5502\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.1045 - val_accuracy: 0.5472\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0797 - val_accuracy: 0.5518\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.1270 - val_accuracy: 0.5463\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.0952 - val_accuracy: 0.5542\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.0646 - val_accuracy: 0.5628\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.5620\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.1632 - val_accuracy: 0.5579\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.0910 - val_accuracy: 0.5697\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.1503 - val_accuracy: 0.5691\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.5683\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.1504 - val_accuracy: 0.5599\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.2181 - val_accuracy: 0.5602\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.1821 - val_accuracy: 0.5634\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.2234 - val_accuracy: 0.5534\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 15s 77ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2509 - val_accuracy: 0.5557\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 15s 76ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.2324 - val_accuracy: 0.5632\n"
     ]
    }
   ],
   "source": [
    "plain_resnet_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "plain_history_34 = plain_resnet_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "insured-department",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "195/195 [==============================] - 26s 108ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.6048\n",
      "Epoch 2/20\n",
      "195/195 [==============================] - 16s 83ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9230 - val_accuracy: 0.6091\n",
      "Epoch 3/20\n",
      "195/195 [==============================] - 16s 83ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.9509 - val_accuracy: 0.6090\n",
      "Epoch 4/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9337 - val_accuracy: 0.6125\n",
      "Epoch 5/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.9315 - val_accuracy: 0.6146\n",
      "Epoch 6/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.0121 - val_accuracy: 0.6029\n",
      "Epoch 7/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.0091 - val_accuracy: 0.6022\n",
      "Epoch 8/20\n",
      "195/195 [==============================] - 16s 83ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.9862 - val_accuracy: 0.6133\n",
      "Epoch 9/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.9855 - val_accuracy: 0.6086\n",
      "Epoch 10/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.0062 - val_accuracy: 0.6114\n",
      "Epoch 11/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.0010 - val_accuracy: 0.6148\n",
      "Epoch 12/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.9732 - val_accuracy: 0.6153\n",
      "Epoch 13/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.0488 - val_accuracy: 0.6175\n",
      "Epoch 14/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9751 - val_accuracy: 0.6124\n",
      "Epoch 15/20\n",
      "195/195 [==============================] - 16s 83ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.9728 - val_accuracy: 0.6116\n",
      "Epoch 16/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.6109\n",
      "Epoch 17/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0709 - val_accuracy: 0.6061\n",
      "Epoch 18/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0677 - val_accuracy: 0.6109\n",
      "Epoch 19/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0217 - val_accuracy: 0.6095\n",
      "Epoch 20/20\n",
      "195/195 [==============================] - 16s 84ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.0925 - val_accuracy: 0.6080\n"
     ]
    }
   ],
   "source": [
    "resnet_34.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.01, clipnorm=1.),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history_34 = resnet_34.fit(\n",
    "    ds_train,\n",
    "    steps_per_epoch=int(ds_info.splits['train'].num_examples/BATCH_SIZE),\n",
    "    validation_steps=int(ds_info.splits['test'].num_examples/BATCH_SIZE),\n",
    "    epochs=EPOCH,\n",
    "    validation_data=ds_test,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-registrar",
   "metadata": {},
   "source": [
    "34 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sonic-driver",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_34.history['loss'], 'r')\n",
    "plt.plot(plain_history_34.history['loss'], 'b')\n",
    "plt.title('Model training loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['resnet_34', 'plainnet_34'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-organ",
   "metadata": {},
   "source": [
    "resnet으로 학습한 결과는 처음부터 loss가 작았으며 epoch수가 증가할 수록 아주 미미하게 loss가 줄어드는 것을 볼 수 있다.  \n",
    "반면에 residual block을 제거한 plain net 은 loss가 0.03부터 시작하다 epoch이 늘어날수록 loss가 초반에 급격히 줄다가 천천히 줄어드는 모습을 볼 수 있다.   \n",
    "여기서 알 수 있는 것은,  resnet 논문 저자들의 말대로 layer가 깊다고 무조건 좋은 것은 아니라는 것이 증명 되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
